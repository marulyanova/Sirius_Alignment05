{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1818712-0214-4e40-b391-097e21878162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T08:04:26.364018Z",
     "iopub.status.busy": "2024-10-16T08:04:26.363161Z",
     "iopub.status.idle": "2024-10-16T08:04:26.495458Z",
     "shell.execute_reply": "2024-10-16T08:04:26.494798Z",
     "shell.execute_reply.started": "2024-10-16T08:04:26.363992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce005f9b685484d893b05068a932b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "import wandb\n",
    "wandb.login(key=\"your_wandb_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c09ec67-b1f3-4ee4-8cf8-0ed9f45a8e0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:48:14.103703Z",
     "iopub.status.busy": "2024-10-16T11:48:14.102963Z",
     "iopub.status.idle": "2024-10-16T11:48:14.156882Z",
     "shell.execute_reply": "2024-10-16T11:48:14.156228Z",
     "shell.execute_reply.started": "2024-10-16T11:48:14.103682Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9046aff8-5436-49dc-8ea7-1711c4943062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:48:14.885547Z",
     "iopub.status.busy": "2024-10-16T11:48:14.884918Z",
     "iopub.status.idle": "2024-10-16T11:48:14.936393Z",
     "shell.execute_reply": "2024-10-16T11:48:14.935758Z",
     "shell.execute_reply.started": "2024-10-16T11:48:14.885524Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/jupyter/datasphere/project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a32b8b-ba23-496e-bc2d-6f9d871d210d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 -q\n",
    "%pip install -U tokenizers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482b809-1663-44fa-a16c-510439c5cb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf794170-9cfd-46f5-b4ca-2d8cb19f7fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install peft accelerate==0.27.2 transformers==4.38.2 protobuf==3.20 bitsandbytes sentencepiece sacrebleu ipython datasets evaluate deepspeed einops  wandb zstandard jsonlines trl==0.7.4 tokenizers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9a029-3bba-4529-a7e9-4d4687a07e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/jupyter/datasphere/project/modpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320af7d-55bc-4954-8c67-fad0d45ccbf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade tyro -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6036a0-78ff-4982-87c1-78a60defe04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sh scripts/modpo/beavertails/run.sh\n",
    "# Reward Modeling: Run DPO on safe preferences to train a safe reward model that encourages safe response\n",
    "%run ./scripts/examples/dpo/dpo.py \\\n",
    "    --sft_model_name \"haoranxu/X-ALMA-13B-Pretrain\" \\\n",
    "    --prompt_template \"Translate this from Russian to English:\\nRussian: {raw_prompt} \\nEnglish:\" \\\n",
    "    --dataset_name \"marulyanova/PKU-SafeRLHF-10K-Modified-xcomet\" \\\n",
    "    --sanity_check False \\\n",
    "    --max_length 512 \\\n",
    "    --peft_config.r 64 \\\n",
    "    --peft_config.target_modules q_proj k_proj v_proj o_proj \\\n",
    "    --peft_config.lora_alpha 1 \\\n",
    "    --peft_config.lora_dropout 0\n",
    "    # --training_args.output_dir \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/xcomet\" \\\n",
    "    # --training_args.run_name \"PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/xcomet\" \\\n",
    "    # --training_args.per_device_train_batch_size 1 \\\n",
    "    # --training_args.per_device_eval_batch_size 1 \\\n",
    "    # --training_args.gradient_accumulation_steps 1 \\\n",
    "    # --training_args.learning_rate 5e-4\n",
    "    # --config_name \"scripts/accelerate_configs/multi_gpu.yaml\" \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f7d0b-aabe-45f2-94f6-1df45b3fcbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sh scripts/modpo/beavertails/run.sh\n",
    "# Reward Modeling: Run DPO on safe preferences to train a safe reward model that encourages safe response\n",
    "%run ./scripts/examples/dpo/dpo.py \\\n",
    "    --sft_model_name \"haoranxu/X-ALMA-13B-Pretrain\" \\\n",
    "    --prompt_template \"Translate this from Russian to English:\\nRussian: {raw_prompt} \\nEnglish:\" \\\n",
    "    --dataset_name \"marulyanova/PKU-SafeRLHF-10K-Modified-kiwi\" \\\n",
    "    --sanity_check False \\\n",
    "    --max_length 512 \\\n",
    "    --peft_config.r 64 \\\n",
    "    --peft_config.target_modules q_proj k_proj v_proj o_proj \\\n",
    "    --peft_config.lora_alpha 1 \\\n",
    "    --peft_config.lora_dropout 0\n",
    "    # --training_args.output_dir \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/kiwi\" \\\n",
    "    # --training_args.run_name \"PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/kiwi\" \\\n",
    "    # --training_args.per_device_train_batch_size 1 \\\n",
    "    # --training_args.per_device_eval_batch_size 1 \\\n",
    "    # --training_args.gradient_accumulation_steps 1 \\\n",
    "    # --training_args.learning_rate 5e-4\n",
    "    # --config_name \"scripts/accelerate_configs/multi_gpu.yaml\" \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b15e7-313d-4552-b809-ed14f3ee59b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Language Modeling: Run MODPO on helpful preferences, with the safe reward as margin, to train language models that are both helpful and safe\n",
    "# r = (w)r_better + (1-w)r_safer\n",
    "%run scripts/modpo/beavertails/modpo.py \\\n",
    "    --sft_model_name \"haoranxu/X-ALMA-13B-Pretrain\" \\\n",
    "    --margin_reward_model_name_1 \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/xcomet/best_checkpoint\" \\\n",
    "    --margin_reward_model_name_2 \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/kiwi/best_checkpoint\" \\\n",
    "    --prompt_template \"Translate this from Russian to English:\\nRussian: {raw_prompt} \\nEnglish:\" \\\n",
    "    --dataset_name \"marulyanova/PKU-SafeRLHF-10K-Modified-fluency\" \\\n",
    "    --sanity_check False \\\n",
    "    --w1 0.33 \\\n",
    "    --w2 0.33 \\\n",
    "    --max_length 512 \\\n",
    "    --peft_config.r 64 \\\n",
    "    --peft_config.target_modules q_proj k_proj v_proj o_proj \\\n",
    "    --peft_config.lora_alpha 1 \\\n",
    "    --peft_config.lora_dropout 0\n",
    "    # --training_args.output_dir \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/lm/($w)better+(1-$w)safer\" \\\n",
    "    # --training_args.run_name PKU-Alignment/PKU-SafeRLHF-10K/modpo/lm/($w)better+(1-$w)safer \\\n",
    "    # --training_args.per_device_train_batch_size 1 \\\n",
    "    # --training_args.per_device_eval_batch_size 1 \\\n",
    "    # --training_args.gradient_accumulation_steps 1 \\\n",
    "    # --training_args.learning_rate 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001e9e1d-fb0e-4b6c-9d65-385c3c7ae09b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T13:22:48.939634Z",
     "iopub.status.busy": "2024-10-16T13:22:48.939210Z",
     "iopub.status.idle": "2024-10-16T13:22:48.949198Z",
     "shell.execute_reply": "2024-10-16T13:22:48.948578Z",
     "shell.execute_reply.started": "2024-10-16T13:22:48.939614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
